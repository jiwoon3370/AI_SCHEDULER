// server/index.js
import express from "express";
import dotenv from "dotenv";
import cors from "cors";
import fetch from "node-fetch";
import multer from "multer";
import helmet from "helmet";

dotenv.config();

const app = express();
const PORT = process.env.PORT || 5000;

// âœ… ë¯¸ë“¤ì›¨ì–´
app.use(express.json());
app.use(helmet());
app.use(cors({
  origin: [
    "https://ai-scheduler.netlify.app", // âœ… Netlify ë„ë©”ì¸
    "http://localhost:5173"
  ],
  methods: ["GET", "POST"],
}));

// âœ… íŒŒì¼ ì—…ë¡œë“œìš© multer ì„¤ì •
const upload = multer({ storage: multer.memoryStorage() });

// âœ… ê¸°ë³¸ ë¼ìš°íŠ¸
app.get("/", (req, res) => {
  res.send("AI Scheduler backend is running âœ…");
});

// âœ… AI ìš”ì²­ ì²˜ë¦¬ ì˜ˆì‹œ
app.post("/api/chat", async (req, res) => {
  try {
    const { message } = req.body;

    const response = await fetch("https://openrouter.ai/api/v1/chat/completions", {
      method: "POST",
      headers: {
        "Authorization": `Bearer ${process.env.OPENROUTER_API_KEY}`,
        "Content-Type": "application/json",
      },
      body: JSON.stringify({
        model: "gpt-4o-mini",
        messages: [{ role: "user", content: message }],
      }),
    });

    const data = await response.json();
    res.json(data);
  } catch (err) {
    console.error("âŒ Chat API Error:", err);
    res.status(500).json({ error: "Server error" });
  }
});

// âœ… íŒŒì¼ ì—…ë¡œë“œ ì˜ˆì‹œ (ì„ íƒì‚¬í•­)
app.post("/api/upload", upload.single("file"), (req, res) => {
  if (!req.file) return res.status(400).send("No file uploaded.");
  console.log("ðŸ“ File received:", req.file.originalname);
  res.json({ message: "File uploaded successfully!" });
});

// âœ… ì„œë²„ ì‹œìž‘
app.listen(PORT, () => {
  console.log(`ðŸš€ Server running on port ${PORT}`);
});
